{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Subject Data Diagnostics\n",
        "\n",
        "This notebook runs diagnostic checks to identify potential data quality issues with specific subjects.\n",
        "\n",
        "## Motivation\n",
        "Subject 7 (A07T) appears to have issues affecting model performance. We run two specific checks:\n",
        "- **Check A**: Channel Variance (\"Loose Wire\" Test) - Detects channels with abnormal signal power\n",
        "- **Check B**: Ghost Label Test - Verifies that labels actually separate the data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "%matplotlib inline\n",
        "plt.style.use('seaborn-v0_8-whitegrid')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load Subject Data\n",
        "\n",
        "We compare a \"good\" subject (A03T) against the potentially \"bad\" subject (A07T).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load \"Good\" Subject vs \"Bad\" Subject\n",
        "sub_good = np.load('../data/processed/A03T.npz')\n",
        "sub_bad  = np.load('../data/processed/A07T.npz')\n",
        "\n",
        "X_good = sub_good['X']  # (Trials, Channels, Time)\n",
        "X_bad  = sub_bad['X']\n",
        "\n",
        "print(f\"A03T (Good): X shape = {X_good.shape}, y shape = {sub_good['y'].shape}\")\n",
        "print(f\"A07T (Bad):  X shape = {X_bad.shape}, y shape = {sub_bad['y'].shape}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## Check A: Channel Variance (\"Loose Wire\" Test)\n",
        "\n",
        "Compare the signal power of each channel between subjects. A bad channel (loose electrode, disconnection, or artifact) will show variance that is 10x-100x higher or lower than other channels.\n",
        "\n",
        "**What to look for:** If one point on the Red line is 10x-100x higher (or lower) than the others, that channel is breaking Euclidean Alignment.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Compute variance per channel (averaged over trials)\n",
        "var_good = np.var(X_good, axis=(0, 2))\n",
        "var_bad  = np.var(X_bad, axis=(0, 2))\n",
        "\n",
        "# Plot\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(var_good, label='A03T (Good)', marker='o')\n",
        "plt.plot(var_bad, label='A07T (Bad)', marker='x', color='red')\n",
        "plt.xlabel('Channel Index')\n",
        "plt.ylabel('Signal Variance')\n",
        "plt.title('Diagnostic: Detecting Exploding Channels')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.yscale('log')  # Log scale is crucial to see outliers\n",
        "plt.show()\n",
        "\n",
        "# Print the offender\n",
        "if np.max(var_bad) > 10 * np.median(var_bad):\n",
        "    bad_ch = np.argmax(var_bad)\n",
        "    print(f\"⚠️ DETECTED BAD CHANNEL IN A07T: Index {bad_ch} has variance {np.max(var_bad):.2f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## Check B: The \"Ghost Label\" Test\n",
        "\n",
        "Check if the labels are actually separating the data by plotting average ERPs (Event-Related Potentials) for different classes.\n",
        "\n",
        "**What to look for:**\n",
        "- **Good (A03):** Distinct differences between Left and Right class lines\n",
        "- **Bad (A07):** If lines overlap perfectly, labels might be shuffled or signal is pure noise\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plot Average ERP for Left vs Right\n",
        "plt.figure(figsize=(12, 4))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "# Channel 7 (C3) is usually motor dominant\n",
        "plt.plot(X_bad[sub_bad['y']==0].mean(axis=0)[7], label='Left (Class 0)') \n",
        "plt.plot(X_bad[sub_bad['y']==1].mean(axis=0)[7], label='Right (Class 1)')\n",
        "plt.title('Subject 7: Class Separation (C3)')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(X_good[sub_good['y']==0].mean(axis=0)[7], label='Left') \n",
        "plt.plot(X_good[sub_good['y']==1].mean(axis=0)[7], label='Right')\n",
        "plt.title('Subject 3: Class Separation (C3)')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## Quantify Class Separation\n",
        "\n",
        "Measure the correlation between class ERPs - lower correlation means more distinct classes.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Quantify class separation using correlation\n",
        "erp_bad_0 = X_bad[sub_bad['y']==0].mean(axis=0)[7]\n",
        "erp_bad_1 = X_bad[sub_bad['y']==1].mean(axis=0)[7]\n",
        "erp_good_0 = X_good[sub_good['y']==0].mean(axis=0)[7]\n",
        "erp_good_1 = X_good[sub_good['y']==1].mean(axis=0)[7]\n",
        "\n",
        "corr_bad = np.corrcoef(erp_bad_0, erp_bad_1)[0, 1]\n",
        "corr_good = np.corrcoef(erp_good_0, erp_good_1)[0, 1]\n",
        "\n",
        "print(\"=\" * 50)\n",
        "print(\"CLASS SEPARATION ANALYSIS\")\n",
        "print(\"=\" * 50)\n",
        "print(f\"\\nCorrelation between class ERPs (lower = more distinct):\")\n",
        "print(f\"  A03T (Good): {corr_good:.4f}\")\n",
        "print(f\"  A07T (Bad):  {corr_bad:.4f}\")\n",
        "\n",
        "if corr_bad > 0.95:\n",
        "    print(f\"\\n⚠️  WARNING: A07T class ERPs are nearly identical (corr={corr_bad:.3f})\")\n",
        "    print(\"    This suggests labels may be shuffled or signal contains no class info!\")\n",
        "elif corr_bad > 0.8:\n",
        "    print(f\"\\n⚠️  CAUTION: A07T shows weak class separation (corr={corr_bad:.3f})\")\n",
        "else:\n",
        "    print(f\"\\n✓ A07T shows reasonable class separation (corr={corr_bad:.3f})\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## Summary\n",
        "\n",
        "Based on the diagnostics above, determine:\n",
        "\n",
        "1. **Bad Channels**: Are there channels with abnormal variance that need interpolation or removal?\n",
        "2. **Label Issues**: Do the labels actually separate the neural signals?\n",
        "3. **Next Steps**: Based on findings, consider:\n",
        "   - Robust preprocessing (channel rejection, artifact removal)\n",
        "   - Subject-specific normalization\n",
        "   - Excluding problematic subjects from training\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check 1: Covariance Matrix Structure\n",
        "# Euclidean Alignment depends on the covariance matrix - let's compare them\n",
        "\n",
        "def compute_trial_covariance(X):\n",
        "    \"\"\"Compute average covariance matrix across trials\"\"\"\n",
        "    n_trials, n_channels, n_times = X.shape\n",
        "    covs = []\n",
        "    for trial in range(n_trials):\n",
        "        cov = np.cov(X[trial])  # (channels, channels)\n",
        "        covs.append(cov)\n",
        "    return np.mean(covs, axis=0)\n",
        "\n",
        "cov_good = compute_trial_covariance(X_good)\n",
        "cov_bad = compute_trial_covariance(X_bad)\n",
        "\n",
        "# Eigenvalue analysis - if eigenvalues are very different, EA will struggle\n",
        "eig_good = np.linalg.eigvalsh(cov_good)\n",
        "eig_bad = np.linalg.eigvalsh(cov_bad)\n",
        "\n",
        "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
        "\n",
        "# Plot eigenvalue spectra\n",
        "ax = axes[0]\n",
        "ax.semilogy(sorted(eig_good, reverse=True), 'o-', label='A03T', markersize=5)\n",
        "ax.semilogy(sorted(eig_bad, reverse=True), 'x-', label='A07T', color='red', markersize=5)\n",
        "ax.set_xlabel('Eigenvalue Index')\n",
        "ax.set_ylabel('Eigenvalue (log scale)')\n",
        "ax.set_title('Covariance Eigenvalue Spectrum')\n",
        "ax.legend()\n",
        "ax.grid(True, alpha=0.3)\n",
        "\n",
        "# Condition number (ratio of max/min eigenvalue) - high = ill-conditioned\n",
        "cond_good = np.max(eig_good) / np.max(eig_good[eig_good > 1e-10])\n",
        "cond_bad = np.max(eig_bad) / np.max(eig_bad[eig_bad > 1e-10])\n",
        "\n",
        "# Plot covariance matrices\n",
        "ax = axes[1]\n",
        "im = ax.imshow(cov_good, cmap='RdBu_r', aspect='auto')\n",
        "ax.set_title(f'A03T Covariance')\n",
        "plt.colorbar(im, ax=ax)\n",
        "\n",
        "ax = axes[2]\n",
        "im = ax.imshow(cov_bad, cmap='RdBu_r', aspect='auto')\n",
        "ax.set_title(f'A07T Covariance')\n",
        "plt.colorbar(im, ax=ax)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(f\"Condition number (higher = harder to align):\")\n",
        "print(f\"  A03T: {np.max(eig_good)/np.min(eig_good[eig_good > 0]):.2f}\")\n",
        "print(f\"  A07T: {np.max(eig_bad)/np.min(eig_bad[eig_bad > 0]):.2f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check 2: Signal-to-Noise Ratio (Fisher's criterion)\n",
        "# Measures how separable the classes are\n",
        "\n",
        "def fisher_score_per_channel(X, y):\n",
        "    \"\"\"Compute Fisher's discriminant ratio for each channel\"\"\"\n",
        "    classes = np.unique(y)\n",
        "    n_channels = X.shape[1]\n",
        "    \n",
        "    scores = []\n",
        "    for ch in range(n_channels):\n",
        "        # Flatten time dimension\n",
        "        x_ch = X[:, ch, :].mean(axis=1)  # Average over time -> (trials,)\n",
        "        \n",
        "        # Between-class variance\n",
        "        class_means = [x_ch[y == c].mean() for c in classes]\n",
        "        overall_mean = x_ch.mean()\n",
        "        between_var = sum([(m - overall_mean)**2 for m in class_means])\n",
        "        \n",
        "        # Within-class variance\n",
        "        within_var = sum([x_ch[y == c].var() for c in classes])\n",
        "        \n",
        "        scores.append(between_var / (within_var + 1e-10))\n",
        "    \n",
        "    return np.array(scores)\n",
        "\n",
        "fisher_good = fisher_score_per_channel(X_good, sub_good['y'])\n",
        "fisher_bad = fisher_score_per_channel(X_bad, sub_bad['y'])\n",
        "\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.bar(np.arange(len(fisher_good)) - 0.2, fisher_good, 0.4, label='A03T (Good)', alpha=0.8)\n",
        "plt.bar(np.arange(len(fisher_bad)) + 0.2, fisher_bad, 0.4, label='A07T (Bad)', alpha=0.8, color='red')\n",
        "plt.xlabel('Channel Index')\n",
        "plt.ylabel('Fisher Score (higher = more discriminative)')\n",
        "plt.title('Per-Channel Class Discriminability')\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.show()\n",
        "\n",
        "print(f\"Total Fisher Score (sum across channels):\")\n",
        "print(f\"  A03T: {fisher_good.sum():.4f}\")\n",
        "print(f\"  A07T: {fisher_bad.sum():.4f}\")\n",
        "print(f\"  Ratio (Good/Bad): {fisher_good.sum()/fisher_bad.sum():.2f}x\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check 3: Compare ALL subjects to see where Subject 7 falls\n",
        "import os\n",
        "\n",
        "subjects = ['A01T', 'A02T', 'A03T', 'A04T', 'A05T', 'A06T', 'A07T', 'A08T', 'A09T']\n",
        "fisher_scores = []\n",
        "cov_condition_numbers = []\n",
        "\n",
        "for subj in subjects:\n",
        "    data = np.load(f'../data/processed/{subj}.npz')\n",
        "    X, y = data['X'], data['y']\n",
        "    \n",
        "    # Fisher score\n",
        "    fs = fisher_score_per_channel(X, y).sum()\n",
        "    fisher_scores.append(fs)\n",
        "    \n",
        "    # Covariance condition number\n",
        "    cov = compute_trial_covariance(X)\n",
        "    eigs = np.linalg.eigvalsh(cov)\n",
        "    cond = np.max(eigs) / np.min(eigs[eigs > 0])\n",
        "    cov_condition_numbers.append(cond)\n",
        "\n",
        "# Plot\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "# Fisher scores\n",
        "ax = axes[0]\n",
        "colors = ['red' if 'A07' in s else 'steelblue' for s in subjects]\n",
        "bars = ax.bar(subjects, fisher_scores, color=colors)\n",
        "ax.set_ylabel('Total Fisher Score')\n",
        "ax.set_title('Class Discriminability by Subject\\n(Higher = Better Signal)')\n",
        "ax.axhline(np.mean(fisher_scores), color='gray', linestyle='--', label='Mean')\n",
        "ax.legend()\n",
        "ax.grid(True, alpha=0.3, axis='y')\n",
        "\n",
        "# Condition numbers  \n",
        "ax = axes[1]\n",
        "bars = ax.bar(subjects, cov_condition_numbers, color=colors)\n",
        "ax.set_ylabel('Condition Number')\n",
        "ax.set_title('Covariance Matrix Condition Number\\n(Higher = Harder to Align)')\n",
        "ax.axhline(np.mean(cov_condition_numbers), color='gray', linestyle='--', label='Mean')\n",
        "ax.legend()\n",
        "ax.grid(True, alpha=0.3, axis='y')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Summary table\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"SUBJECT COMPARISON SUMMARY\")\n",
        "print(\"=\"*60)\n",
        "print(f\"{'Subject':<10} {'Fisher Score':<15} {'Cov Condition':<15}\")\n",
        "print(\"-\"*60)\n",
        "for i, subj in enumerate(subjects):\n",
        "    marker = \" ⚠️\" if 'A07' in subj else \"\"\n",
        "    print(f\"{subj:<10} {fisher_scores[i]:<15.4f} {cov_condition_numbers[i]:<15.2f}{marker}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## Interpretation Guide\n",
        "\n",
        "### What the deeper diagnostics reveal:\n",
        "\n",
        "1. **Covariance Eigenvalue Spectrum**: If A07T has a very different spectrum (much steeper or flatter), Euclidean Alignment will have trouble mapping it to other subjects.\n",
        "\n",
        "2. **Condition Number**: High condition number = covariance matrix is nearly singular = numerical instability in EA's matrix square root operation.\n",
        "\n",
        "3. **Fisher Score**: Low Fisher = the subject's brain signals don't clearly differentiate between left/right motor imagery. This is **BCI illiteracy** - ~15-30% of people have weak motor imagery signals.\n",
        "\n",
        "### Likely Conclusions:\n",
        "- If A07T has **low Fisher score** → The subject is a weak motor imagery performer (nothing wrong with data, just biology)\n",
        "- If A07T has **high condition number** → EA is numerically unstable for this subject\n",
        "- If A07T looks **normal** on all metrics → The issue may be model-specific, not data-specific\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## Deeper Diagnostic: All Subjects Comparison\n",
        "\n",
        "Since no obvious issues were found, let's compare ALL subjects to see if A07T is truly an outlier or just a naturally \"hard\" subject (BCI illiteracy).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "eeg-mi",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
